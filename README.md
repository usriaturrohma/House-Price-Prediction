# ğŸ¡ House Price Prediction

This project is part of the Kaggle competition [Home Data for ML Course](https://www.kaggle.com/competitions/home-data-for-ml-course), aimed at building a machine learning model to predict house prices in Ames, Iowa, based on various property features.

---

## ğŸ“Œ Project Overview

Accurately predicting house prices is a classic regression problem in data science. This project demonstrates the application of exploratory data analysis, feature engineering, and regression modeling to predict housing prices using the Ames Housing dataset.

---

## ğŸ“Š Dataset

The dataset contains 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa. The target variable is:

- `SalePrice` â€“ the property's sale price in USD.

ğŸ“ Key files:
- `train.csv` â€“ Training data with features and target variable.
- `test.csv` â€“ Test data for which predictions are to be made.

---

## âš™ï¸ Tools & Libraries

- Python 3.x
- Jupyter Notebook
- pandas, numpy
- matplotlib, seaborn
- scikit-learn
- XGBoost / LightGBM (optional for advanced modeling)

---

## ğŸ” Methodology

1. **Data Cleaning** â€“ Handling missing values, outliers, and inconsistent data.
2. **Exploratory Data Analysis (EDA)** â€“ Understanding distributions, correlations, and variable importance.
3. **Feature Engineering** â€“ Transforming skewed data, encoding categoricals, scaling numeric features.
4. **Modeling** â€“ Using multiple regression algorithms:
    - Linear Regression
    - Ridge & Lasso Regression
    - Decision Trees / Random Forest
    - Gradient Boosting (XGBoost / LightGBM)
5. **Model Evaluation** â€“ Using RMSE and cross-validation.

---

## ğŸ“ˆ Results

- Final model achieves competitive Root Mean Squared Error (RMSE) on the test dataset.
- Feature importance plot shows key predictors such as `OverallQual`, `GrLivArea`, and `GarageCars`.

---

## ğŸ§  Key Learnings

- The importance of feature preprocessing and outlier removal.
- Regularization techniques (Lasso/Ridge) help reduce overfitting.
- Gradient boosting methods outperform linear models in many cases.

---

## ğŸš€ How to Run

```bash
# Install required packages
pip install -r requirements.txt

# Launch notebook
jupyter notebook house-price-prediction.ipynb
````

---

## ğŸ“‚ Project Structure

```
house-price-prediction/
â”‚
â”œâ”€â”€ house-price-prediction.ipynb   # Main notebook
â”œâ”€â”€ train.csv                      # Training data
â”œâ”€â”€ test.csv                       # Test data
â”œâ”€â”€ requirements.txt               # Required Python packages
â”œâ”€â”€ .gitignore                     # Files to exclude from git
â””â”€â”€ README.md                      # Project documentation
```

---

## ğŸ Credits

* Competition hosted by [Kaggle](https://www.kaggle.com/competitions/home-data-for-ml-course)
* Dataset: Ames Housing Dataset by Dean De Cock

---

## ğŸ“¬ Contact

Created by **\[Usriatur Rohma]**
ğŸ“§ Email: \[usriaturrohmah13@gmail.com(mailto:usriaturrohmah13@gmail.com)]
ğŸ”— LinkedIn: \[[Usriatur Rohma](https://www.linkedin.com/in/usriaturrohma/)]

---


